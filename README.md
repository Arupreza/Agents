# ðŸ¤– Agentic AI Learning Repository

A comprehensive exploration of agentic AI systems using LangChain, LangGraph, and modern LLM frameworks.

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![LangChain](https://img.shields.io/badge/LangChain-Latest-green.svg)
![LangGraph](https://img.shields.io/badge/LangGraph-Latest-orange.svg)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-purple.svg)
![Gemini](https://img.shields.io/badge/Google-Gemini-4285F4.svg?logo=google)
![Llama](https://img.shields.io/badge/Meta-Llama-0467DF.svg?logo=meta)
![Tavily](https://img.shields.io/badge/Tavily-Search-FF6B6B.svg)

---

### 8. Corrective RAG (CRAG) (`9.LG_CorrectiveRAG/`)

```
[ User Question ]
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   retrieve          â”‚ â† VectorStoreRetriever: FAISS similarity search
â”‚   (Node)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ grade_documents     â”‚ â† LLM judges: "relevant" or "not relevant"
â”‚ (Node)              â”‚    for each retrieved doc
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ decide_to_generate  â”‚ â† Conditional Edge (Router)
â”‚ (Decision Gate)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                    â”‚
      â”‚ "web_search"       â”‚ "generate"
      â†“                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  web_search     â”‚   â”‚     generate        â”‚ â† LLM synthesizes answer
â”‚  (Node)         â”‚   â”‚     (Node)          â”‚    from relevant docs
â”‚  Tavily API     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â†“
      â”‚                        [ END ]
      â”‚
      â””â”€â”€â†’ generate (with web results)
```

**Workflow Logic**:
```python
if any_doc_relevant:
    # At least one doc is relevant
    if all_docs_relevant:
        # All docs relevant â†’ direct generation
        return "generate"
    else:
        # Some docs irrelevant â†’ augment with web search
        return "web_search"
else:
    # No relevant docs â†’ fallback to web search only
    return "web_search"
```

**Key Components**:

**Chains** (Modular Prompt + LLM combinations):
- `retrieval_grader.py`: Binary classifier (relevant/not relevant) with structured output
- `generation.py`: RAG chain that synthesizes answer from context

**Nodes** (Graph execution units):
- `retrieve.py`: Fetches top-k documents from FAISS vector store
- `grade_documents.py`: Filters documents, keeps only relevant ones
- `web_search.py`: Falls back to Tavily search when retrieval insufficient
- `generate.py`: Final answer generation with context

**Architecture Benefits**:
- **Self-Correcting**: Validates retrieval quality before generation
- **Hybrid Approach**: Combines local knowledge (FAISS) + real-time web search
- **Modular Design**: Chains and nodes are independently testable
- **Structured Outputs**: Pydantic models ensure reliable grading (binary: yes/no)
- **Performance Metrics**: LangSmith tracing shows retrieval (2.97s) and grading overhead (5.68s)

**State Flow**:
```python
class GraphState(TypedDict):
    question: str              # User query
    documents: List[Document]  # Retrieved docs
    generation: str            # Final answer
    web_search: str           # Flag: "Yes" to trigger search
```

---

## ðŸ“š Learning Journey

This repository documents my exploration of building intelligent agents with various architectures and capabilities.

### ðŸŽ¯ Core Concepts Explored

```mermaid
graph TD
    A[Agentic AI] --> B[ReAct Pattern]
    A --> C[RAG Systems]
    A --> D[Reflection]
    A --> E[Function Calling]
    B --> F[Web Search Agents]
    C --> G[Document Indexing]
    D --> H[Self-Critique]
    E --> I[Tool Integration]
```

---

## ðŸ—‚ï¸ Repository Structure

### 1. **ReAct Pattern Implementations**
- `1.LC_WebSearchAgentReact.py` - LangChain-based ReAct agent with web search
- `2.LC_WebSearchAgentFunctionCalling.py` - Function-calling variant of ReAct
- `6.LG_ReActFunctionCalling.py` - LangGraph implementation with function calling

**Key Learning**: ReAct (Reasoning + Acting) enables agents to iteratively reason about problems and take actions based on observations.

### 2. **RAG (Retrieval-Augmented Generation)**
- `3.LC_RAGAgent.py` - Basic RAG implementation
- `4.FiassIndexingHNSWOpenai.py` - FAISS vector indexing with HNSW algorithm

**Key Learning**: RAG combines retrieval mechanisms with generation, enabling agents to access external knowledge bases dynamically.

### 3. **Reflection Mechanisms**
- `7.LG_ReflectionAgent.py` - Self-reflective agent with critique capability
- `8.LG_ReflexionAgent.py` - Enhanced reflexion pattern

**Key Learning**: Reflection patterns allow agents to critique and improve their own outputs through iterative refinement.

### 4. **Corrective RAG (CRAG)**
- `9.LG_CorrectiveRAG/` - Corrective RAG with fallback web search
  - `chains/generation.py` - Answer generation chain
  - `chains/retrieval_grader.py` - Document relevance grading
  - `nodes/generate.py` - Generation node
  - `nodes/grade_documents.py` - Document grading node
  - `nodes/retrieve.py` - Vector store retrieval
  - `nodes/web_search.py` - Fallback web search
  - `main.py` - Complete CRAG workflow

**Key Learning**: Corrective RAG evaluates retrieval quality and falls back to web search when local knowledge is insufficient, combining best of both retrieval and search paradigms.

---

## ðŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Framework** | LangChain, LangGraph |
| **LLM Providers** | OpenAI (GPT-4), Google Gemini, Meta Llama |
| **Vector Store** | FAISS with HNSW indexing |
| **Search Tools** | Tavily Search API |
| **Custom Tools** | Structured tool integration |
| **State Management** | LangGraph StateGraph |

---

## ðŸ—ï¸ Architecture Patterns

### 1. ReAct Agent with LangGraph (`1.LC_WebSearchAgentReact.py`)

```
System Prompt (ReAct Instructions)
          â†“
User Query â†’ Agent Node (LLM with Tools)
          â†“
    Decision Point
          â†“
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â”‚           â”‚
Tool Calls?   No Tool Calls
    â”‚           â”‚
    â†“           â†“
Tool Node    END (Final Response)
    â”‚
    â†“
Tool Results â†’ Agent Node (Reasoning)
    â”‚
    â””â”€â”€â†’ (Loop until complete)
```

**Key Components**:
- **State Management**: `AgentState` with message accumulation via `add_messages`
- **Conditional Routing**: `should_continue()` checks for tool calls
- **Graph Structure**: Agent â†” Tools cyclic connection until termination
- **Tool Binding**: LLM bound to tools via `.bind_tools()`
- **Declarative Flow**: LangGraph handles execution loop automatically

---

### 2. Function Calling Agent (`2.LC_WebSearchAgentFunctionCalling.py`)

```
[ User Query ]
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Initialize State    â”‚ â† System Prompt + Message History
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   REASONING         â”‚ â† LLM: "What should I do next?"
â”‚  (llm_with_tools)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
   Decision
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          â”‚          â”‚
Tool Calls?â”‚    Final Answer?
â”‚          â”‚          â”‚
â†“          â”‚          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ACTION (ACT)      â”‚  â”‚  Output to User     â”‚
â”‚ - Find Tool         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ - Validate Args     â”‚            â†“
â”‚ - Execute .invoke() â”‚         [ END ]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OBSERVATION       â”‚
â”‚ - Add ToolMessage   â”‚
â”‚ - Append to History â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
      â””â”€â”€â†’ Back to REASONING (Loop)
```

**Key Components**:
- **Model Agnostic**: Factory pattern supports OpenAI, Anthropic, Google via `get_model()`
- **Explicit Loop Control**: Manual `while` loop with iteration tracking and max_iterations safety
- **Tool Execution**: Decoupled `_execute_tool_call()` method for extensibility
- **State Persistence**: All messages (System, Human, AI, Tool) tracked in AgentState
- **Provider Switching**: Change one line to swap LLM providers

**Variable Flow**:
```
Persistent State:
- messages [List]: Conversation memory
- max_iterations [Int]: Safety limit (default: 10)

System-Sourced:
- system_prompt [Str]: Agent behavioral instructions
- tool_args [Dict]: Extracted from response.tool_calls["args"]
- tool_result [Str]: Output from tool.function.invoke()

Human-Sourced:
- user_query [Str]: Initial task

Brain-Sourced (LLM):
- response.content [Str]: Text generation
- response.tool_calls [List]: Function call requests with id and args
```

---

### 3. RAG Agent (`3.LC_RAGAgent.py`)

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  search_papers      â”‚ â† Tool decorated with @tool
â”‚  (Vector Search)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FAISS.similarity    â”‚ â† Retrieve top-k documents
â”‚ _search(query, k=3) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Retrieved Docs      â”‚ â† Source + Page + Content
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM (Gemini)       â”‚ â† Generate answer with context
â”‚  + System Prompt    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Final Answer        â”‚ â† With citations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Components**:
- **Vector Store**: FAISS loaded from pre-built index
- **Embeddings**: OpenAI `text-embedding-3-small` for queries
- **Tool Definition**: `@tool` decorator wraps retrieval function
- **Agent Creation**: Modern `create_agent()` with `system_prompt` parameter
- **Message Format**: Invoked with `{"messages": [("user", query)]}`

---

### 4. FAISS Vector Indexing (`4.FiassIndexingHNSWOpenai.py`)

```
[ PDF Documents ]
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DirectoryLoader     â”‚ â† Load all PDFs from directory
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Text Splitter       â”‚ â† chunk_size=800, overlap=120
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Batch Processing    â”‚ â† Process BATCH_SIZE chunks at a time
â”‚ (Prevents Timeout)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
      Loop for each batch:
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI Embeddings   â”‚ â† text-embedding-3-small (dim=1536)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FAISS HNSW Index    â”‚ â† IndexHNSWFlat with M=64, efConstruction=200
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ vectorstore.add     â”‚ â† Add batch to index
â”‚ _documents(batch)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
      time.sleep(0.5)  â† Rate limit protection
      â†“
[ Next Batch or Save ]
```

**Key Components**:
- **HNSW Algorithm**: Fast approximate nearest neighbor search
- **Batch Processing**: Prevents API timeouts and respects rate limits
- **Configurable**: BATCH_SIZE, chunk_size, overlap adjustable
- **Persistence**: Saves to disk with `save_local()`, loads with `load_local()`
- **Parameters**: M=64 (connections per node), efConstruction=200 (build quality)

---

### 5. LangGraph ReAct with Function Calling (`6.LG_ReActFunctionCalling.py`)

```
[ START ]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  agent_reason       â”‚ â† LLM with tools + System prompt
â”‚  (Node)             â”‚    "Should I use a tool or answer?"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ should_continue?    â”‚ â† Conditional Edge (Router)
â”‚ (Decision Gate)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚              â”‚
    â”‚ "ACT"        â”‚ "END"
    â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”
â”‚   act       â”‚  â”‚ END â”‚ â† Final result
â”‚ (ToolNode)  â”‚  â””â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â””â”€â”€â†’ Back to agent_reason (Loop)
```

**Key Components**:
- **Multi-Tool Support**: Combines Tavily Search + custom fahrenheit_converter
- **System Prompt Engineering**: Enforces specific tool usage sequence
- **Conditional Router**: `Literal["ACT", "END"]` type hints for clarity
- **Tool Execution**: Prebuilt `ToolNode` handles automatic tool invocation
- **Loop Mechanism**: `add_edge("act", "agent_reason")` creates reasoning loop
- **Recursion Limit**: Configurable safety via `config={"recursion_limit": 10}`

---

### 6. Reflection Agent (`7.LG_ReflectionAgent.py`)

```
[ START ]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GENERATE (Node)    â”‚ â† generation_chain: Write/Revise tweet
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Condition Check:    â”‚ â† len(messages) >= 6?
â”‚ messages >= 6?      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚              â”‚
    â”‚ YES          â”‚ NO
    â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ END â”‚      â”‚  REFLECT    â”‚ â† reflection_chain: Critique
â””â”€â”€â”€â”€â”€â”˜      â”‚  (Node)     â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â””â”€â”€â†’ Back to GENERATE (Loop)
```

**Key Components**:
- **Dual Chains**: Separate prompts for generation vs reflection
- **Message Accumulation**: `add_messages` annotation appends instead of overwrites
- **Iteration Limit**: Stops at 6 messages (3 generate-reflect cycles)
- **Prompt Engineering**: System prompts define critic vs creator personas
- **HumanMessage Wrapping**: Reflection output wrapped as HumanMessage for generator

---

### 7. Reflexion Agent (`8.LG_ReflexionAgent.py`)

```
[ START ]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  draft (Node)       â”‚ â† first_responder: Answer + Reflection + Queries
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ execute_tools       â”‚ â† run_queries: Batch Tavily searches
â”‚ (ToolNode)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  revise (Node)      â”‚ â† revisor: Incorporate search results + Citations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ event_loop          â”‚ â† Check ToolMessage count
â”‚ (Conditional)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                â”‚
    â”‚ count >= 2     â”‚ count < 2
    â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ END â”‚      â”‚ execute_toolsâ”‚ â† Loop back for more research
â””â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â””â”€â”€â†’ Back to revise
```

**Key Components**:
- **Structured Outputs**: Pydantic models (Reflection, AnswerQuestion, ReviseAnswer)
- **Tool Choice Enforcement**: `tool_choice="AnswerQuestion"` forces structured response
- **Batch Search**: `run_queries()` processes multiple queries via `.batch()`
- **Self-Reflection Schema**: Missing/superfluous fields guide improvement
- **Citation System**: Numerical references [1], [2] with References section
- **Iteration Control**: Limits to 2 tool executions via ToolMessage count
- **Temporal Context**: `datetime.now().isoformat()` in prompt for time-aware responses

---

## ðŸš€ Quick Start

```bash
# Clone repository
git clone https://github.com/Arupreza/Agents.git
cd Agents

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Add your API keys:
# - OPENAI_API_KEY
# - GEMINI_API_KEY
# - TAVILY_API_KEY
```

---

## ðŸŽ“ Key Takeaways

1. **Progressive Complexity**: Started with simple ReAct loops, progressed to multi-agent reflection systems
2. **Framework Comparison**: Explored both LangChain's imperative style and LangGraph's declarative approach
3. **Model Agnosticism**: Built provider-agnostic agents supporting OpenAI, Anthropic, and Google
4. **Tool Integration**: Learned web search, vector retrieval, and custom tool creation
5. **Prompt Engineering**: Discovered system prompts critically shape agent behavior
6. **State Management**: Mastered message accumulation patterns and iteration control
7. **Production Considerations**: Implemented batch processing, rate limiting, and error handling

---

## ðŸ“– Learning Resources

- [LangChain Documentation](https://python.langchain.com/)
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [ReAct Paper](https://arxiv.org/abs/2210.03629): "ReAct: Synergizing Reasoning and Acting in Language Models"
- [RAG Paper](https://arxiv.org/abs/2005.11401): "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
- [Reflexion Paper](https://arxiv.org/abs/2303.11366): "Reflexion: Language Agents with Verbal Reinforcement Learning"

---

## ðŸ”® Future Directions

- [ ] Multi-agent collaboration and communication protocols
- [ ] Long-term memory mechanisms (vector + graph hybrid)
- [ ] Production deployment patterns (FastAPI + Docker)
- [ ] Agent evaluation frameworks and benchmarking
- [ ] Rust implementations for performance-critical components
- [ ] Cost optimization strategies for production LLM systems

---

## ðŸ“„ License

MIT License - See LICENSE file for details

---

**Note**: This repository represents active learning. Code quality and patterns evolve as understanding deepens.